{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You sould have spark installed in your server or your computer\n",
    "# for the example here the spark installed in google could servers.\n",
    "\n",
    "import findspark # you need to install this one by pip install findspark \n",
    "findspark.init('/home/sak/spark-2.4.3-bin-hadoop2.7') # set your path \n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_example').getOrCreate()\n",
    "from pyspark import SparkContext \n",
    "sc= spark.sparkContext\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, split\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Title='Innovation in Database Management: Computer Science vs. Engineering.', Conference='VLDB'),\n",
       " Row(Title='High performance prime field multiplication for GPU.', Conference='ISCAS'),\n",
       " Row(Title='enchanted scissors: a scissor interface for support in cutting and interactive fabrication.', Conference='SIGGRAPH'),\n",
       " Row(Title='Detection of channel degradation attack by Intermediary Node in Linear Networks.', Conference='INFOCOM'),\n",
       " Row(Title='Pinning a Complex Network through the Betweenness Centrality Strategy.', Conference='ISCAS')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spark.read.csv(\"research_paper.csv\", inferSchema=True, header=True) # importing the data from your computer/server\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|               Title|Conference|\n",
      "+--------------------+----------+\n",
      "|Innovation in Dat...|      VLDB|\n",
      "|High performance ...|     ISCAS|\n",
      "|enchanted scissor...|  SIGGRAPH|\n",
      "|Detection of chan...|   INFOCOM|\n",
      "|Pinning a Complex...|     ISCAS|\n",
      "|Analysis and Desi...|     ISCAS|\n",
      "|Dynamic bluescreens.|  SIGGRAPH|\n",
      "|A Quantitative As...|   INFOCOM|\n",
      "|Automatic sanitiz...|       WWW|\n",
      "|A &#916;&#931; IR...|     ISCAS|\n",
      "|Architecture of a...|     ISCAS|\n",
      "|Rule-based Servic...|       WWW|\n",
      "|Business Policy M...|      VLDB|\n",
      "|A high speed and ...|     ISCAS|\n",
      "|PREDIcT: Towards ...|      VLDB|\n",
      "|SocialSensor: sen...|       WWW|\n",
      "|Parametric keyfra...|  SIGGRAPH|\n",
      "|An Explanation fo...|   INFOCOM|\n",
      "|Hot Block Cluster...|      VLDB|\n",
      "|Analysis of propa...|     ISCAS|\n",
      "+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"research_paper.csv\", inferSchema=True, header=True)\n",
    "dataPd = pd.read_csv(\"research_paper.csv\")\n",
    "data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Conference: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Conference|count|\n",
      "+----------+-----+\n",
      "|     ISCAS|  864|\n",
      "|   INFOCOM|  515|\n",
      "|      VLDB|  423|\n",
      "|       WWW|  379|\n",
      "|  SIGGRAPH|  326|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col \n",
    "data.groupBy(\"Conference\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Title|Conference|\n",
      "+-----+----------+\n",
      "|    0|         0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "data.select([count(when(isnan(c), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|               title|Conference|\n",
      "+--------------------+----------+\n",
      "|innovation in dat...|      vldb|\n",
      "|high performance ...|     iscas|\n",
      "|enchanted scissor...|  siggraph|\n",
      "|detection of chan...|   infocom|\n",
      "|pinning a complex...|     iscas|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "def clean_text(c):\n",
    "  c = lower(c)\n",
    "  c = regexp_replace(c, \"^rt \", \"\")\n",
    "  c = regexp_replace(c, \"(https?\\://)\\S+\", \"\")\n",
    "  c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
    "  \n",
    "\n",
    "  return c\n",
    "\n",
    "data1 = data.select((clean_text(col(\"title\")).alias(\"title\")), ((clean_text(col(\"Conference\")).alias(\"Conference\"))))\n",
    "\n",
    "data1.show(5)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+-----+\n",
      "|               Title|Conference|               words|            filtered|            features|label|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+-----+\n",
      "|Innovation in Dat...|      VLDB|[innovation, in, ...|[innovation, data...|(791,[32,40,184,4...|  2.0|\n",
      "|High performance ...|     ISCAS|[high, performanc...|[high, performanc...|(791,[16,42,301,3...|  0.0|\n",
      "|enchanted scissor...|  SIGGRAPH|[enchanted, sciss...|[enchanted, sciss...|(791,[87,330,405]...|  4.0|\n",
      "|Detection of chan...|   INFOCOM|[detection, of, c...|[detection, chann...|(791,[1,38,46,80,...|  1.0|\n",
      "|Pinning a Complex...|     ISCAS|[pinning, a, comp...|[pinning, complex...|(791,[13,103,782]...|  0.0|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"Title\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "# stop words\n",
    "remover = StopWordsRemover()\n",
    "stopwords = remover.getStopWords()  \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(stopwords)\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"Conference\", outputCol = \"label\")\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(data)\n",
    "dataset = pipelineFit.transform(data)\n",
    "dataset.show(5)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 1756\n",
      "Test Dataset Count: 751\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|                         Title|Conference|                   probability|label|prediction|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|Front-end amplifier of low-...|     ISCAS|[0.9873925466446979,0.00332...|  0.0|       0.0|\n",
      "|Low-voltage SOI CMOS DTMOS/...|     ISCAS|[0.9742686991022053,0.00850...|  0.0|       0.0|\n",
      "|A low power multi-mode CMOS...|     ISCAS|[0.9674492923760447,0.01337...|  0.0|       0.0|\n",
      "|P<sup>2</sup>E-DWT: A paral...|     ISCAS|[0.9659249230169219,0.00634...|  0.0|       0.0|\n",
      "|A continuous-time band-pass...|     ISCAS|[0.962968104908483,0.008284...|  0.0|       0.0|\n",
      "|WL-VC SRAM: a low leakage m...|     ISCAS|[0.9606127886621211,0.00716...|  0.0|       0.0|\n",
      "|Design of process variation...|     ISCAS|[0.9604440270461447,0.01587...|  0.0|       0.0|\n",
      "|Split-ADC Digital Backgroun...|     ISCAS|[0.9579038172854173,0.00757...|  0.0|       0.0|\n",
      "|Code division parallel delt...|     ISCAS|[0.9568771961418872,0.00538...|  0.0|       0.0|\n",
      "|Improved hybrid coding sche...|     ISCAS|[0.956053637454894,0.013767...|  0.0|       0.0|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Title\",\"Conference\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650884770005698"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+---------------------+-----+----------+\n",
      "|                         Title|Conference|          probability|label|prediction|\n",
      "+------------------------------+----------+---------------------+-----+----------+\n",
      "|A Compact On-Chip Capacitiv...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A framework for benchmarkin...|       WWW|[1.0,0.0,0.0,0.0,0.0]|  3.0|       0.0|\n",
      "|A Fast and reliable switchi...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A 10 Gb/s optical receiver ...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A Capacitor-free CMOS Low-d...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A continuous-time band-pass...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A 10-bit 2GHz Current-Steer...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A 20-MS/s sigma delta modul...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A Low Jitter CMOS PLL Clock...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|A 7.5mW, 11-bit continuous-...|     ISCAS|[1.0,0.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "+------------------------------+----------+---------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5279728595964894"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 30)\n",
    "dtModel = dt.fit(trainingData)\n",
    "predictions = dtModel.transform(testData)\n",
    "predictions.select(\"Title\",\"Conference\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|                         Title|Conference|                   probability|label|prediction|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "|Low-voltage SOI CMOS DTMOS/...|     ISCAS|[0.9999999719795253,2.55481...|  0.0|       0.0|\n",
      "|A low power multi-mode CMOS...|     ISCAS|[0.9999998440207164,1.17117...|  0.0|       0.0|\n",
      "|A novel structure for the d...|     ISCAS|[0.999998052448344,1.710033...|  0.0|       0.0|\n",
      "|Front-end amplifier of low-...|     ISCAS|[0.9999954888419709,1.92638...|  0.0|       0.0|\n",
      "|Adaptive Low/High Voltage S...|     ISCAS|[0.9999937641443432,6.27888...|  0.0|       0.0|\n",
      "|Improved hybrid coding sche...|     ISCAS|[0.9999918143518555,2.69522...|  0.0|       0.0|\n",
      "|Dynamic sawtooth compensati...|     ISCAS|[0.9999900448691628,4.86796...|  0.0|       0.0|\n",
      "|A continuous-time band-pass...|     ISCAS|[0.9999756264204607,1.36908...|  0.0|       0.0|\n",
      "|Design of process variation...|     ISCAS|[0.9999721157708871,2.26873...|  0.0|       0.0|\n",
      "|Low frequency, current mode...|     ISCAS|[0.9999705561636928,8.22004...|  0.0|       0.0|\n",
      "+------------------------------+----------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7635266573430473"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Title\",\"Conference\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
